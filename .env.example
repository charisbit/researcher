ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Ollama 配置
USE_LOCAL_MODEL=false
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_API_KEY=ollama

# 设置为 true 以使用本地 Ollama 模型
# USE_LOCAL_MODEL=true